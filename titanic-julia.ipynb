{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "using Statistics\n",
    "using DiffOpt\n",
    "using Flux\n",
    "using Flux: onecold, binarycrossentropy, throttle, logitcrossentropy, crossentropy\n",
    "using Base.Iterators: repeated\n",
    "using JuMP\n",
    "using SCS\n",
    "using CSV\n",
    "using DataFrames\n",
    "using ChainRulesCore"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = NaN;   # hack for the SVM"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## custom SVM layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SVM"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "    SVM as a Flux layer\n",
    "\"\"\"\n",
    "function SVM(X::AbstractMatrix{T}; model = Model(() -> diff_optimizer(SCS.Optimizer))) where {T}\n",
    "    D, N = size(X)\n",
    "    \n",
    "    Y = vec([y >= 0.5 ? 1 : -1 for y in labels]')\n",
    "    # scale class from 0,1 to -1,1. required for SVM\n",
    "    \n",
    "    # model init\n",
    "    empty!(model)\n",
    "    set_optimizer_attribute(model, MOI.Silent(), true)\n",
    "    \n",
    "    # add variables\n",
    "    @variable(model, l[1:N])\n",
    "    @variable(model, w[1:D])\n",
    "    @variable(model, b)\n",
    "    \n",
    "    @constraint(model, cons, Y.*(X'*w .+ b) + l.-1 ∈ MOI.Nonnegatives(N))\n",
    "    @constraint(model, 1.0*l ∈ MOI.Nonnegatives(N));\n",
    "    \n",
    "    @objective(\n",
    "        model,\n",
    "        Min,\n",
    "        sum(l),\n",
    "    )\n",
    "\n",
    "    optimize!(model)\n",
    "\n",
    "    wv = value.(w)\n",
    "    bv = value(b)\n",
    "    \n",
    "    return (X'*wv .+ bv)' #prediction\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "function ChainRulesCore.rrule(::typeof(SVM), X::AbstractArray{T}; model = Model(() -> diff_optimizer(SCS.Optimizer))) where {T}\n",
    "\n",
    "    predictions = SVM(X, model=model) \n",
    "    \n",
    "    function pullback_SVM(dX)\n",
    "        \"\"\"\n",
    "            model[:w], model[:b] are the weights of this layer\n",
    "            they are not updated using backward pass\n",
    "            since they can be computed to an accurate degree using a solver\n",
    "        \"\"\"\n",
    "        dy = zero(dX)   # since w#\n",
    "        return (NO_FIELDS, dy)\n",
    "    end\n",
    "    return predictions, pullback_SVM\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "function fetchProblem(;split_ratio::Float64)\n",
    "    df = CSV.File(\"titanic_preprocessed.csv\") |> DataFrame\n",
    "\n",
    "    Y = df[:, 2]\n",
    "    X = df[!, 3:12]\n",
    "    X = Matrix(X)'\n",
    "\n",
    "    D, N = size(X)\n",
    "\n",
    "    l = Int(floor(length(Y)*split_ratio))\n",
    "    return X[:, 1:l], X[:, l+1:N], Y[1:l]', Y[l+1:N]'\n",
    "end\n",
    "X_train, X_test, Y_train, Y_test = fetchProblem(split_ratio=0.8)\n",
    "D = size(X_train)[1];"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define the NN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "m = Chain(\n",
    "    Dense(D, 16, relu),\n",
    "    Dropout(0.5),\n",
    "    SVM\n",
    "#     Dense(32, 1, σ),\n",
    ");"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "#47 (generic function with 1 method)"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loss(x, y) = logitcrossentropy(m(x), y) \n",
    "opt = ADAM(); # popular stochastic gradient descent variant\n",
    "\n",
    "classify(x::Float64) = (x>=0.5) ? 1 : 0\n",
    "\n",
    "function accuracy(x, y_true)\n",
    "    y_pred = classify.(m(x))\n",
    "    return sum(y_true .≈ y_pred) / length(y_true)\n",
    "end\n",
    "\n",
    "dataset = repeated((X_train,Y_train), 1) # repeat the data set, very low accuracy on the orig dataset\n",
    "evalcb = () -> @show(loss(X_train,Y_train)) # callback to show loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "┌ Warning: problem status: ALMOST_OPTIMAL\n",
      "└ @ DiffOpt /home/pika/Projects/DiffOpt.jl/src/MOI_wrapper.jl:633\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss(X_train, Y_train) = 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "┌ Warning: problem status: ALMOST_OPTIMAL\n",
      "└ @ DiffOpt /home/pika/Projects/DiffOpt.jl/src/MOI_wrapper.jl:633\n",
      "┌ Warning: problem status: ALMOST_OPTIMAL\n",
      "└ @ DiffOpt /home/pika/Projects/DiffOpt.jl/src/MOI_wrapper.jl:633\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy(X_train, Y_train) = 0.7697715289982425\n",
      "accuracy(X_test, Y_test) = 0.8391608391608392\n"
     ]
    }
   ],
   "source": [
    "labels = Y_train   # needed for SVM\n",
    "for iter in 1:1\n",
    "    Flux.train!(loss, params(m), dataset, opt, cb = throttle(evalcb, 5)); #took me ~5 minutes to train on CPU\n",
    "end\n",
    "\n",
    "@show accuracy(X_train, Y_train)\n",
    "\n",
    "labels = Y_test   # needed for SVM\n",
    "@show accuracy(X_test, Y_test);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Julia 1.6.1",
   "language": "julia",
   "name": "julia-1.6"
  },
  "language_info": {
   "file_extension": ".jl",
   "mimetype": "application/julia",
   "name": "julia",
   "version": "1.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
